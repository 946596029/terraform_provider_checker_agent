# 2026.01.06 开发日志

## 阶段三
 * `目标`
  - 1. 使用 prompt 进行一次对话
 * `步骤`
  - 1. 
 * `问题` -
  - 1. prompt 一般具有哪些要素？
    一次 prompt 通常包含以下元素：
      - **指令（Instruction）**：明确告诉模型要做什么任务
      - **上下文（Context）**：提供背景信息，帮助模型理解任务
        - 角色（Role）：定义 AI 的角色和身份
        - 场景（Scenario）：描述使用场景和环境
        - 约束（Constraints）：限制条件和规则
      - **输入（Input）**：具体的输入数据或问题
      - **输出（Output）**：期望的输出格式和示例
      - **示例（Examples）**：few-shot 示例，展示期望的行为
      - **格式要求（Format）**：指定输出格式（JSON、Markdown 等）
  
  - 2. 如何使 LLM 效果更好？
    最佳实践：
      - **清晰明确**：使用具体、明确的指令，避免歧义
      - **结构化组织**：使用分隔符、标题、列表等结构化 prompt
      - **提供示例**：使用 few-shot learning，给出输入输出示例
      - **分步思考**：复杂任务分解为多个步骤，使用 Chain of Thought
      - **角色设定**：为 AI 设定明确的角色和专业领域
      - **输出约束**：明确指定输出格式、长度、语言等要求
      - **错误处理**：指导模型如何处理边界情况和错误
      - **迭代优化**：根据实际效果不断调整和优化 prompt
      
  - 3. Prompt 示例
    ```txt
    角色：你是一位专业的 [领域] 专家

    任务：[具体任务描述]

    上下文：
    - [背景信息 1]
    - [背景信息 2]

    输入：
    [具体输入内容]

    输出要求：
    - 格式：[JSON/Markdown/代码等]
    - 语言：[中文/英文等]
    - 长度：[具体要求]

    示例：
    输入：[示例输入]
    输出：[示例输出]

    请按照以上要求完成任务。
    ```
  
  - 4. prompt 使用什么格式比较好？
    不同格式的优缺点和适用场景：

      **1. 普通文本格式（Plain Text）**
        - 优点：
        - 简单直接，易于编写和阅读
        - LLM 理解自然，无需额外解析
        - 适合大多数对话场景
        - 灵活性强，可以自由组织内容
        - 缺点：
        - 结构化程度低，难以程序化处理
        - 缺少明确的语义分隔
        - 不适合复杂的模板化场景
        - 适用场景：
        - 简单的单次对话
        - 自由格式的 prompt
        - 快速原型开发
        
      **2. Markdown 格式**
        - 优点：
        - 结构化清晰，层次分明（标题、列表、代码块等）
        - 人类可读性强，易于维护
        - LLM 对 Markdown 理解良好
        - 支持代码高亮、表格等丰富格式
        - 便于版本控制和协作
        - 缺点：
        - 需要一定的 Markdown 语法知识
        - 对于简单 prompt 可能过于复杂
        - 适用场景：
        - 复杂的、多层次的 prompt
        - 需要清晰结构的 prompt 模板
        - 包含代码示例的 prompt
        - 团队协作和文档化需求
        - **推荐用于大多数场景**
        
      **3. JSON 格式**
        - 优点：
        - 结构化程度最高，易于程序化处理
        - 可以精确控制每个字段
        - 便于模板化和参数化
        - 适合自动化生成 prompt
        - 缺点：
        - 人类可读性较差
        - LLM 需要额外解析 JSON
        - 编写和维护成本较高
        - 不适合直接作为 prompt 内容
        - 适用场景：
        - Prompt 模板系统（存储结构，渲染为文本）
        - 需要程序化生成 prompt 的场景
        - 配置驱动的 prompt 管理
        - **不推荐直接作为 prompt 内容发送给 LLM**
        
      **推荐方案：**
        - **存储格式**：使用 JSON 或 YAML 存储 prompt 模板和配置
        - **发送格式**：将模板渲染为 **Markdown 格式**的文本发送给 LLM
        - **原因**：
        - Markdown 在可读性和结构化之间取得最佳平衡
        - LLM 对 Markdown 的理解和处理能力很强
        - 便于人类编写和维护
        - 支持丰富的格式表达（代码块、列表、表格等）
        
      **示例对比：**
        
        ```markdown
        # 角色
        你是一位专业的 Terraform 专家。
        
        # 任务
        分析以下 Terraform 配置，检查是否存在问题。
        
        # 输入
        ```hcl
        resource "aws_instance" "example" {
        ami           = "ami-12345678"
        instance_type = "t2.micro"
        }
        ```
        
        # 输出要求
        - 格式：JSON
        - 包含字段：issues, severity, suggestions
        ```
        
        这种 Markdown 格式既清晰又易于 LLM 理解。

