# 2026.01.14 开发日志

## 阶段七
### 目标 - 结合设计流程，实现检查流程
  - 实现 provider implement 部分检查流程
-----------------------------------------------------
### 步骤
  - [ ] 分析全量测试出现的问题
  - [ ] 根据问题的分析结果确定流程的关键节点
  - [ ] 
  - [ ] 
-----------------------------------------------------
### 完成情况
  - 
-----------------------------------------------------
### 问题
  - 为什么上下文长度越大，理解的效果就越差？
    - 业界的总结：上下文长度越大，注意力效果越差
    - 我的猜测：
      - 模型更关注`结构信息`，不关注`过程信息`，因为模型的`短期记忆`有限
      - 但如果结合模型是做概率分布的话？说`短期记忆`又不太合理，因为既然是机器的机制，应该不受记忆的限制
        - 想了一下，我觉得是因为现在的模型都是基于 `Transformer` 机制来理解内容的
        - `Transformer` 受限于词表，不可能容入太多的特征数据，所以推理部分会不断地压缩输入内容，而这部分应该是有一个固定的损失率的
          - 受计算宽度限制？？我觉得应该还受状态空间数量，关联关系的限制
        - 结合厂商为了追求大上下文做的优化技术，还会造成其他的信息损失
    - 解决的办法
      - 压缩信息密度（预合成高阶特征向量？？）
        - 结构化信息
        - 总结信息密度低的内容
      - 任务逻辑分离
        - 模型不能做的事情，只能人把事情拆分
  - 