# 2026.01.14 开发日志

## 阶段七
### 目标 - 结合设计流程，实现检查流程
  - 分析全量分析结果，来确认问题
  - 实现 provider implement 部分检查流程
-----------------------------------------------------
### 步骤
  - [ ] 分析全量测试出现的问题
  - [ ] 根据问题的分析结果确定流程的关键节点
    - [x] 问题1 上下文太大，文本内容太复杂，模型无法确定解范围
      - [x] 切割一个小的文本
      - [x] 手工选择相关的规则
      - [x] 组装 prompt 测试
      - [x] 测试模型类型（通用文生文模型，编码方向微调过的文生文模型）
    - [ ] 问题2 预期模型可以对一个函数的结构进行规范检查
      - [ ] 
  - [ ] 设计检查流程
    - [ ] 需要的工具
      - [ ] 编写代码切分工具
      - [ ] 上下文管理工具
        - [ ] 总结 prompt
        - [ ] 检索 prompt
        - [ ] 历史管理
      - [ ] 多轮对话工具
      - [ ] 接入文本嵌入模型
      - [ ] 
-----------------------------------------------------
### 完成情况
  - 问题1 上下文太大，文本内容太复杂，模型无法确定解范围
    - 测试结果
      - 通用文生文模型
        - 检测出显式声明的代码规范错误
        - 未检测出隐式声明的代码规范错误
      - 编码方向微调过的文生文模型 （**效果更好**）
        - 检测出显式声明的代码规范错误
        - 检测出部分隐式声明的代码规范错误
    - 印证猜测
      - 需要缩小上下文, 以提高注意力效果，提高模型的语义理解能力
        - 上下文越大，模型文本语义理解能力越差
      - 需要使用专门方向的 `llm`，可以提升效果
      - 越贴近末尾的 `prompt`，对结果影响越大
  - 问题2 预期模型可以对一个函数的结构进行规范检查
-----------------------------------------------------
### 问题
  - 为什么上下文长度越大，理解的效果就越差？
    - 业界的总结：上下文长度越大，注意力效果越差
    - 我的猜测：
      - 模型更关注`结构信息`，不关注`过程信息`，因为模型的`短期记忆`有限
      - 但如果结合模型是做概率分布的话？说`短期记忆`又不太合理，因为既然是机器的机制，应该不受记忆的限制
        - 想了一下，我觉得是因为现在的模型都是基于 `Transformer` 机制来理解内容的
        - `Transformer` 受限于词表，不可能容入太多的特征数据，所以推理部分会不断地压缩输入内容，而这部分应该是有一个固定的损失率的
          - 受计算宽度限制？？我觉得应该还受状态空间数量，关联关系的限制
        - 结合厂商为了追求大上下文做的优化技术，还会造成其他的信息损失
    - 解决的办法
      - 压缩信息密度（预合成高阶特征向量？？）
        - 结构化信息
        - 总结信息密度低的内容
      - 任务逻辑分离
        - 模型不能做的事情，只能人把事情拆分
  - **意外发现** 模型是否未多维空间概率分布
    - 像是多维空间概率分布，在使用通用模型进行代码规范检查时，模型出现了前后自相矛盾的现象
      - 模型已经检查出`违背代码规范`的结果，但是用`✔`标识该项规则`通过`
    - 在代码规范中只保留了 md 3级标题，4级标题，通用文生文模型输出的结果也使用 md 格式，从3级标题开始
      - `看起来结果是紧跟在输入后面的，离结果越近的文本，对结果影响越大`
    